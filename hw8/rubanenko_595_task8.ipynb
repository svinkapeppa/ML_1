{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "duJV07Z-CbRb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Rubanenko Evgeny, 595"
      ]
    },
    {
      "metadata": {
        "id": "EQTWZ8jAJ2I8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Check Questions\n",
        "\n",
        "**Вопрос 1:** Чем LSTM лучше/хуже чем обычная RNN?  \n",
        "**Ответ:** Основная проблема RNN - затухающий / взрывающийся градиент. LSTM намного более устойчива к этой проблеме - поэтому ее и стали использовать. Но у нее есть тоже свои минусы - долгие вычисления, множество параметров. Так же LSTM может потерять эффективность, если делать много слоев (обычно делают 2-3). Но сделать RNN, которая будет лучше чем LSTM (так называемая Vanilla RNN) очень сложно.\n",
        "\n",
        "**Вопрос 2:** Выпишите производную $\\frac{\\partial c_{n+1}}{\\partial c_{k}}$ для LSTM http://colah.github.io/posts/2015-08-Understanding-LSTMs/, объясните формулу, когда производная затухает, когда взрывается?  \n",
        "**Ответ:** Будем вместо $c_{n}$ писать $h_{n}$ - так привычнее.  \n",
        "Известно следующее:\n",
        "$$h_{t} = W \\cdot f(h_{t-1}) + W^{(hx)} \\cdot x_{[t]}$$\n",
        "Тогда для $\\frac{\\partial h_{n+1}}{\\partial h_{k}}$ по chain rule сможем написать следующее:\n",
        "$$\\frac{\\partial h_{n+1}}{\\partial h_{k}} = \\prod_{l=k}^{n} \\frac{\\partial h_{l+1}}{\\partial h_{l}}$$\n",
        "По формуле выше сможем переписать произвольную производную из этого произведения следующим образом:\n",
        "$$\\frac{\\partial h_{l+1}}{\\partial h_{l}} = W^{T} f'(h_{l})$$\n",
        "Здесь так же необходимо учесть, что последняя производная на самом деле является Якобианом:\n",
        "$$f'(h_{l}) = \\left(\\frac{\\partial f_{i}}{\\partial x_{j}}\\right)_{(i,j)}, i \\in \\{1..m\\},\\ j \\in \\{1..n\\}$$\n",
        "Учитывая написанное, мы можем оценить норму частной производной:\n",
        "$$\\left|\\left|\\frac{\\partial h_{l+1}}{\\partial h_{l}}\\right|\\right| \\leq \\left|\\left|W^{T}\\right|\\right| \\cdot \\left|\\left|diag(f'(h_{l}))\\right|\\right| \\leq \\beta_{W}\\beta_{h}$$\n",
        "где $\\beta$ есть верхняя граница соответствующей нормы. Тогда для исходной частной производной получаем:\n",
        "$$\\left|\\left|\\frac{\\partial h_{n+1}}{\\partial h_{k}}\\right|\\right| = \\left|\\left|\\prod_{l=k}^{n} \\frac{\\partial h_{l+1}}{\\partial h_{l}}\\right|\\right| \\leq (\\beta_{W}\\beta_{h})^{n - k + 1}$$\n",
        "Если $\\beta_{W}\\beta_{h}$ меньше 1, то при увеличении n будем наблюдать затухающий градиент, а если больше, то взрывающийся.\n",
        "\n",
        "**Вопрос 3:** Зачем нужен TBPTT? Почему BPTT плох?  \n",
        "**Ответ:** Основной проблемой BPTT является стоимость обновления одного параметра - она большая. Из-за этого становится невозможным производить много итераций. Другая проблема - если вход большой, то для одного обновления придется посчитать большое число производных - возникает проблема затухающего / взрывающегося градиента. Победить все это был призван TBPTT. TBPTT разбивает длинный вход на несколько маленьких по длине, и работает с новыми входами как с отдельными задачами. Тогда, если разбивать длинный вход на много маленьких - можно избавиться от проблем стоимости. Также станет больше hidden states - дополнительная информация о далеком прошлом может оказаться полезной.\n",
        "\n",
        "**Вопрос 4:** Как комбинировать рекуррентные и сверточные сети, а главное зачем? Приведите несколько примеров реальных задач.  \n",
        "**Ответ:** Идея состоит в том, что CNN обучается на каких-то пространственных объектах, после чего получаются какие-то их высокоуровневые описания, которые потом подаются на вход RNN, которая либо подробно описывает их, либо просто классифицирует. Комбинирование используется, потому что CNN хорошо работает с пространственно связанными данными, а RNN - с временными сигналам.\n",
        "\n",
        "Возможные задачи:\n",
        "1. По фрагменту видео классифиировать происходящее\n",
        "2. По изображению объекта получить его текстовое описание\n",
        "\n",
        "В последнем случае CNN распознает, что есть на изображении, передает эту информацию в RNN, которая уже генерирует текстовое описание.\n",
        "\n",
        "**Вопрос 5:** Можно ли использовать сверточные сети для классификации текстов? Как решить проблему с произвольной длинной входа?  \n",
        "**Ответ:** Это не является традиционным подходом, но возможно. Сначала текст пройдет некоторый lookup-table (посчитаются вхождения символов из входного текста), а затем пойдут обычные слои CNN, длина текста считается фиксированной. При несовпадении текст либо заполнится какими-то dummy символами, либо разобьется на вектор текстов.\n",
        "\n",
        "**Вопрос 6:** Attention - что это такое, где применяют и как? Приведите пример использования на какой-нибудь задаче.  \n",
        "**Ответ:** Attention применяют в RNN, чтобы побороть типичный bottleneck у RNN: последняя ячейка encoder должна знать всю информацию об input. Идея состоит в том, чтобы давать важным частям входа более высокие веса (т.е. decoder уже не просто смотрит на то, что пришло ему от последнего encoder, а на каждом шаге обращается к нужной части входа).  \n",
        "Типичное применение - NMT. Применяется в NMT, потому что маловерятно, что последний encoder запомнит информацию о первом слове в предложении (например, если вход имел длину 50, то последний encoder должен помнить прошлые 50 шагов). LSTM должны решать проблему с длительными зависимостями, но делают это недостаточно эффективно. Используя Attention, decoder при генерации первого слова обращает больше внимания на первое слово во входе и тд.  \n",
        "Используют также при генерации описания к изображению: CNN кодирует изображение, RNN генерирует описание, а Attention позволяет сильнее фокусироваться на том, описание чего сейчас генерируется."
      ]
    },
    {
      "metadata": {
        "id": "ZuyHit_LRKUs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "5bf8d707-ec69-4111-839a-e721f2fad89c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525529834963,
          "user_tz": -180,
          "elapsed": 2905,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install faker tqdm babel"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.6/dist-packages (0.8.13)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.23.2)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from faker) (1.11.0)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from faker) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.5.3)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel) (2018.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LQgcYbVxrbwQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e57ced9-8b5a-47fe-88fe-fc53218cf8cf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525529839250,
          "user_tz": -180,
          "elapsed": 3177,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import keras.backend as K\n",
        "\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "from faker import Faker\n",
        "\n",
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.layers.core import *\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import *\n",
        "from keras.layers.merge import Multiply\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import TimeDistributed, Multiply"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "g92P9UQPrhHY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'd MMM YYY', \n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n",
        "\n",
        "LOCALES = ['en_US']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z1yCiX3Or0uA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_date():\n",
        "    '''\n",
        "        Creates some fake dates \n",
        "        Returns: tuple containing human readable string,\n",
        "                 machine readable string, and date object\n",
        "    '''\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    try:\n",
        "        human_readable = format_date(dt,\n",
        "                                     format=random.choice(FORMATS),\n",
        "                                     locale=random.choice(LOCALES))\n",
        "\n",
        "        case_change = random.choice([0,1,2])\n",
        "        if case_change == 1:\n",
        "            human_readable = human_readable.upper()\n",
        "        elif case_change == 2:\n",
        "            human_readable = human_readable.lower()\n",
        "\n",
        "        machine_readable = dt.isoformat()\n",
        "    except AttributeError as e:\n",
        "        return None, None, None\n",
        "\n",
        "    return human_readable, machine_readable, dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qzi6jD2suAJJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_dataset(n_examples):\n",
        "    '''\n",
        "        Creates a dataset with n_examples and vocabularies\n",
        "        :n_examples: the number of examples to generate\n",
        "    '''\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "\n",
        "    for i in tqdm(range(n_examples)):\n",
        "        h, m, _ = create_date()\n",
        "        if h is not None:\n",
        "            dataset.append((h, m))\n",
        "            human_vocab.update(tuple(h))\n",
        "            machine_vocab.update(tuple(m))\n",
        "\n",
        "    human = dict(zip(list(human_vocab) + ['<unk>', '<pad>'], \n",
        "                     list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(list(machine_vocab) + ['<unk>', '<pad>']))\n",
        "    machine = {v:k for k,v in inv_machine.items()}\n",
        " \n",
        "    return dataset, human, machine, inv_machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fmm9uUOpuHM6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def string_to_int(string, lenght, vocab):\n",
        "    if len(string) > lenght:\n",
        "        string = string[:lenght]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "    \n",
        "    if len(string) < lenght:\n",
        "        rep += [vocab['<pad>']] * (lenght - len(string))\n",
        "    \n",
        "    return rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3TTVlrqTuIxj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def int_to_string(ints, inv_vocab):\n",
        "    return [inv_vocab[i] for i in ints]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlLz90KPuMxS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Actual data generation"
      ]
    },
    {
      "metadata": {
        "id": "L0qsMytpuKNl",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "dd754967-64fc-4543-8c20-2914158abfa9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525503315976,
          "user_tz": -180,
          "elapsed": 18957,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fake.seed(42)\n",
        "random.seed(42)\n",
        "N = int(3e5)\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(N)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 54%|█████▍    | 161348/300000 [00:09<00:08, 16173.80it/s]/usr/local/lib/python3.6/dist-packages/tqdm/_monitor.py:89: TqdmSynchronisationWarning: Set changed size during iteration (see https://github.com/tqdm/tqdm/issues/481)\n",
            "  TqdmSynchronisationWarning)\n",
            "100%|██████████| 300000/300000 [00:18<00:00, 16134.85it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "w5ykypfkuTFy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b85dad3-c7c8-4031-b2ed-b9df87ca7080",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525503316600,
          "user_tz": -180,
          "elapsed": 595,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tuesday, september 14, 1971', '1971-09-14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "tEY5ximHuZ_P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs, targets = zip(*dataset)\n",
        "inputs = np.array([string_to_int(i, TIME_STEPS, human_vocab) for i in inputs])\n",
        "targets = [string_to_int(t, TIME_STEPS, machine_vocab) for t in targets]\n",
        "targets = np.array(list(map(lambda x: \n",
        "                            to_categorical(x, num_classes=len(machine_vocab)), \n",
        "                            targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UNJUNTPRvMBa",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_valid, y_valid, X_test, y_test = (\n",
        "    inputs[:int(2e5)], targets[:int(2e5)], \n",
        "    inputs[int(2e5):-int(5e4)], targets[int(2e5):-int(5e4)],  \n",
        "    inputs[-int(5e4):], targets[-int(5e4):])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_02VZ3tivxmy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Simple NMT"
      ]
    },
    {
      "metadata": {
        "id": "e7WAUMIdvgLS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EMBEDING = 128\n",
        "ENCODER_UNITS = 128\n",
        "DECODER_UNITS = 128\n",
        "TIME_STEPS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HHz3igUHExE8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Моя первая модель. Дала 86%. Через пару часов я понял,\n",
        "# что просто две LSTM подряд запустил. Так что так себе достижение.\n",
        "def model_simple_nmt_1(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    encoder1 = Embedding(in_chars, ENCODER_UNITS)(inputs)\n",
        "    encoder2 = LSTM(ENCODER_UNITS, return_sequences=True)(encoder1)\n",
        "    decoder1 = LSTM(DECODER_UNITS, return_sequences=True)(encoder2)\n",
        "    outputs = TimeDistributed(Dense(out_chars, activation='softmax'))(decoder1)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDZ-z9DTvs39",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_simple_nmt(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    encoder1 = Embedding(in_chars, EMBEDING)(inputs)\n",
        "    encoder2 = LSTM(ENCODER_UNITS)(encoder1)\n",
        "    encoder3 = RepeatVector(TIME_STEPS)(encoder2)\n",
        "    decoder1 = LSTM(DECODER_UNITS, return_sequences=True)(encoder3)\n",
        "    outputs = TimeDistributed(Dense(out_chars, activation='softmax'))(decoder1)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Idv85_Rtv0vY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e6047e42-b667-47e8-d3b6-4b4e6e70b243",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525503328976,
          "user_tz": -180,
          "elapsed": 1304,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
        "m.compile(optimizer='adam',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 20, 128)           7680      \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "repeat_vector_1 (RepeatVecto (None, 20, 128)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 20, 128)           131584    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 20, 13)            1677      \n",
            "=================================================================\n",
            "Total params: 272,525\n",
            "Trainable params: 272,525\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XVycoqERwBuM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "ecc7806a-4d83-455e-db0c-0e97963d6c94",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525506775487,
          "user_tz": -180,
          "elapsed": 3444396,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit(x=[X_train], y=y_train, validation_data=(X_valid, y_valid),\n",
        "    epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/10\n",
            " 42560/200000 [=====>........................] - ETA: 4:23 - loss: 0.7954 - acc: 0.7149"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "128896/200000 [==================>...........] - ETA: 1:58 - loss: 0.4238 - acc: 0.8442"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 352s 2ms/step - loss: 0.2863 - acc: 0.8957 - val_loss: 0.0219 - val_acc: 0.9923\n",
            "Epoch 2/10\n",
            "   640/200000 [..............................] - ETA: 5:30 - loss: 0.0268 - acc: 0.9905"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83520/200000 [===========>..................] - ETA: 3:11 - loss: 0.0202 - acc: 0.9923"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "161536/200000 [=======================>......] - ETA: 1:03 - loss: 0.0201 - acc: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 347s 2ms/step - loss: 0.0195 - acc: 0.9923 - val_loss: 0.0164 - val_acc: 0.9930\n",
            "Epoch 3/10\n",
            " 13120/200000 [>.............................] - ETA: 5:09 - loss: 0.0157 - acc: 0.9932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86144/200000 [===========>..................] - ETA: 3:06 - loss: 0.0165 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "160128/200000 [=======================>......] - ETA: 1:05 - loss: 0.0171 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 347s 2ms/step - loss: 0.0169 - acc: 0.9927 - val_loss: 0.0158 - val_acc: 0.9929\n",
            "Epoch 4/10\n",
            " 12544/200000 [>.............................] - ETA: 5:05 - loss: 0.0168 - acc: 0.9925"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "101568/200000 [==============>...............] - ETA: 2:41 - loss: 0.0167 - acc: 0.9927"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "177920/200000 [=========================>....] - ETA: 35s - loss: 0.0164 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 345s 2ms/step - loss: 0.0163 - acc: 0.9928 - val_loss: 0.0155 - val_acc: 0.9930\n",
            "Epoch 5/10\n",
            " 19008/200000 [=>............................] - ETA: 4:52 - loss: 0.0158 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100608/200000 [==============>...............] - ETA: 2:41 - loss: 0.0162 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "181696/200000 [==========================>...] - ETA: 29s - loss: 0.0159 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 343s 2ms/step - loss: 0.0159 - acc: 0.9929 - val_loss: 0.0182 - val_acc: 0.9923\n",
            "Epoch 6/10\n",
            " 20672/200000 [==>...........................] - ETA: 4:46 - loss: 0.0176 - acc: 0.9924"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92032/200000 [============>.................] - ETA: 2:52 - loss: 0.0159 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "167872/200000 [========================>.....] - ETA: 51s - loss: 0.0157 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 341s 2ms/step - loss: 0.0159 - acc: 0.9929 - val_loss: 0.0162 - val_acc: 0.9929\n",
            "Epoch 7/10\n",
            " 15168/200000 [=>............................] - ETA: 4:59 - loss: 0.0161 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90048/200000 [============>.................] - ETA: 2:58 - loss: 0.0157 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "164864/200000 [=======================>......] - ETA: 56s - loss: 0.0156 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 343s 2ms/step - loss: 0.0156 - acc: 0.9930 - val_loss: 0.0155 - val_acc: 0.9931\n",
            "Epoch 8/10\n",
            " 13696/200000 [=>............................] - ETA: 5:01 - loss: 0.0155 - acc: 0.9932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86848/200000 [============>.................] - ETA: 3:02 - loss: 0.0152 - acc: 0.9932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "158592/200000 [======================>.......] - ETA: 1:06 - loss: 0.0156 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 342s 2ms/step - loss: 0.0156 - acc: 0.9930 - val_loss: 0.0154 - val_acc: 0.9931\n",
            "Epoch 9/10\n",
            " 11584/200000 [>.............................] - ETA: 5:03 - loss: 0.0151 - acc: 0.9932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84096/200000 [===========>..................] - ETA: 3:06 - loss: 0.0156 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "156096/200000 [======================>.......] - ETA: 1:10 - loss: 0.0155 - acc: 0.9931"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 341s 2ms/step - loss: 0.0155 - acc: 0.9931 - val_loss: 0.0155 - val_acc: 0.9930\n",
            "Epoch 10/10\n",
            " 10176/200000 [>.............................] - ETA: 5:06 - loss: 0.0161 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83392/200000 [===========>..................] - ETA: 3:07 - loss: 0.0155 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "154368/200000 [======================>.......] - ETA: 1:13 - loss: 0.0155 - acc: 0.9931"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 340s 2ms/step - loss: 0.0154 - acc: 0.9931 - val_loss: 0.0154 - val_acc: 0.9930\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f38a7c676d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "yI0r6lHGwHwW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b2f382b6-095a-4b94-c1cd-626686f10201",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525507145689,
          "user_tz": -180,
          "elapsed": 45144,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 45s 891us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.015360312386206642, 0.993050000076294]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "ZO4ZvLt-wI9R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
        "\n",
        "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
        "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)\n",
        "    return int_to_string(prediction, inv_output_vocabulary)\n",
        "\n",
        "def run_examples(model, input_vocabulary,\n",
        "                 inv_output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    for example in examples:\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary,\n",
        "                                             inv_output_vocabulary, example)))\n",
        "        print('input:', example)\n",
        "        print('output:', predicted[-1])\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iwfOxIqNwM9a",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5d4d599a-5c3b-43c6-ee71-ddbea35b16c1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525507171373,
          "user_tz": -180,
          "elapsed": 717,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_examples(m, human_vocab, inv_machine_vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: 3 May 1979\n",
            "output: 1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 5 Apr 09\n",
            "output: 2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 20th February 2016\n",
            "output: 2016-02-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: Wed 10 Jul 2007\n",
            "output: 2007-07-10<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2016-02-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2007-07-10<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "3CPR6Fs0AyPN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NMT with attention"
      ]
    },
    {
      "metadata": {
        "id": "b-E0oFodUE8b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EMBEDING = 128\n",
        "ENCODER_UNITS = 256\n",
        "DECODER_UNITS = 256\n",
        "TIME_STEPS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7HmVdUUrGO3m",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def attention_cell(inputs):\n",
        "    permutation = Permute((2, 1))(inputs)\n",
        "    dense = Dense(TIME_STEPS, activation='softmax')(permutation)\n",
        "    probs = Permute((2, 1))(dense)\n",
        "    output_attention_mul = Multiply()([inputs, probs])\n",
        "    return output_attention_mul"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-79x7r_zBMjj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_attention_nmt(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    embeding = Embedding(in_chars, EMBEDING)(inputs)\n",
        "    lstm = LSTM(ENCODER_UNITS)(embeding)\n",
        "    repeat = RepeatVector(TIME_STEPS)(lstm)\n",
        "    lstm = LSTM(DECODER_UNITS, return_sequences=True)(repeat)\n",
        "    attention = attention_cell(lstm)\n",
        "    outputs = TimeDistributed(Dense(out_chars, activation='softmax'))(attention)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TL_w7svXBIVI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "ef805a98-6df5-42cc-b71d-2c8a7caa024a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525507713597,
          "user_tz": -180,
          "elapsed": 1359,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_attention_nmt(len(human_vocab), len(machine_vocab))\n",
        "m.compile(optimizer='adam',\n",
        "          loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_6 (Embedding)         (None, 20, 128)      7680        input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_11 (LSTM)                  (None, 256)          394240      embedding_6[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_6 (RepeatVector)  (None, 20, 256)      0           lstm_11[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_12 (LSTM)                  (None, 20, 256)      525312      repeat_vector_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "permute_5 (Permute)             (None, 256, 20)      0           lstm_12[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 256, 20)      420         permute_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_6 (Permute)             (None, 20, 256)      0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 20, 256)      0           lstm_12[0][0]                    \n",
            "                                                                 permute_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_3 (TimeDistrib (None, 20, 13)       3341        multiply_1[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 930,993\n",
            "Trainable params: 930,993\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KaKBsa4fBI4F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "78625a02-6248-4cf6-8d98-bb60b18f1c9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525511164243,
          "user_tz": -180,
          "elapsed": 3446110,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit([X_train], y_train, validation_data=(X_valid, y_valid),\n",
        "    epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/10\n",
            " 42880/200000 [=====>........................] - ETA: 4:26 - loss: 0.9509 - acc: 0.6936"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "129600/200000 [==================>...........] - ETA: 1:57 - loss: 0.7253 - acc: 0.7283"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 351s 2ms/step - loss: 0.6789 - acc: 0.7344 - val_loss: 0.5894 - val_acc: 0.7456\n",
            "Epoch 2/10\n",
            "  1024/200000 [..............................] - ETA: 5:22 - loss: 0.5914 - acc: 0.7448"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73792/200000 [==========>...................] - ETA: 3:26 - loss: 0.5057 - acc: 0.7968"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "152448/200000 [=====================>........] - ETA: 1:17 - loss: 0.4423 - acc: 0.8263"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 346s 2ms/step - loss: 0.4193 - acc: 0.8355 - val_loss: 0.3310 - val_acc: 0.8665\n",
            "Epoch 3/10\n",
            "  9600/200000 [>.............................] - ETA: 5:09 - loss: 0.3289 - acc: 0.8667"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93760/200000 [=============>................] - ETA: 2:52 - loss: 0.2766 - acc: 0.8919"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "173184/200000 [========================>.....] - ETA: 43s - loss: 0.2208 - acc: 0.9147"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 344s 2ms/step - loss: 0.2009 - acc: 0.9227 - val_loss: 0.0455 - val_acc: 0.9871\n",
            "Epoch 4/10\n",
            " 16960/200000 [=>............................] - ETA: 4:54 - loss: 0.0325 - acc: 0.9912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90112/200000 [============>.................] - ETA: 2:57 - loss: 0.0216 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "162624/200000 [=======================>......] - ETA: 1:00 - loss: 0.0197 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 343s 2ms/step - loss: 0.0191 - acc: 0.9927 - val_loss: 0.0296 - val_acc: 0.9902\n",
            "Epoch 5/10\n",
            " 13120/200000 [>.............................] - ETA: 5:05 - loss: 0.0249 - acc: 0.9911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 97344/200000 [=============>................] - ETA: 2:46 - loss: 0.0173 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "175488/200000 [=========================>....] - ETA: 39s - loss: 0.0168 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 344s 2ms/step - loss: 0.0169 - acc: 0.9928 - val_loss: 0.0158 - val_acc: 0.9930\n",
            "Epoch 6/10\n",
            " 18176/200000 [=>............................] - ETA: 4:53 - loss: 0.0154 - acc: 0.9932"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92736/200000 [============>.................] - ETA: 2:53 - loss: 0.0156 - acc: 0.9931"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "166144/200000 [=======================>......] - ETA: 54s - loss: 0.0157 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 342s 2ms/step - loss: 0.0158 - acc: 0.9930 - val_loss: 0.0157 - val_acc: 0.9930\n",
            "Epoch 7/10\n",
            " 14400/200000 [=>............................] - ETA: 5:00 - loss: 0.0167 - acc: 0.9926"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 89984/200000 [============>.................] - ETA: 2:57 - loss: 0.0162 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "164480/200000 [=======================>......] - ETA: 57s - loss: 0.0157 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 342s 2ms/step - loss: 0.0157 - acc: 0.9930 - val_loss: 0.0156 - val_acc: 0.9929\n",
            "Epoch 8/10\n",
            " 13952/200000 [=>............................] - ETA: 5:02 - loss: 0.0158 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 86400/200000 [===========>..................] - ETA: 3:04 - loss: 0.0160 - acc: 0.9928"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "158656/200000 [======================>.......] - ETA: 1:06 - loss: 0.0157 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 342s 2ms/step - loss: 0.0157 - acc: 0.9930 - val_loss: 0.0155 - val_acc: 0.9930\n",
            "Epoch 9/10\n",
            " 11328/200000 [>.............................] - ETA: 5:00 - loss: 0.0159 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85888/200000 [===========>..................] - ETA: 3:02 - loss: 0.0160 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "157504/200000 [======================>.......] - ETA: 1:08 - loss: 0.0157 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 341s 2ms/step - loss: 0.0157 - acc: 0.9930 - val_loss: 0.0154 - val_acc: 0.9930\n",
            "Epoch 10/10\n",
            " 11072/200000 [>.............................] - ETA: 5:08 - loss: 0.0157 - acc: 0.9929"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "146496/200000 [====================>.........] - ETA: 1:28 - loss: 0.0155 - acc: 0.9930"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 349s 2ms/step - loss: 0.0155 - acc: 0.9930 - val_loss: 0.0154 - val_acc: 0.9931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f389d1b2c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "qkyYGTWPBMCz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "36b5c6d8-ebb0-4ab7-89c5-bf4a397eaee0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525511225703,
          "user_tz": -180,
          "elapsed": 44746,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 44s 884us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.015390844363240758, 0.9930530004501342]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "iXZ-3Z08CVa4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Report\n",
        "\n",
        "Simple NMT:\n",
        "* Какого-то подбора параметров или манипуляций со слоями мне делать не пришлось. Как только я написал правильную модель (со второго раза, первая была неправильной), я сразу получил требуемое accuracy.\n",
        "\n",
        "Attention NMT:\n",
        "* Реализовал Attention так, как предлагалось в домашней работе - добавил дополнительный слой. Ничего подбирать не пришлось - сразу получилось нужное accuracy.\n",
        "\n",
        "Comparison:\n",
        "* Так как с помощью Simple NMT можно добиться того же результата, что и с помощью Attention NMT, но притом потратить меньше времени, то в данном случае разумнее использовать Simple NMT. Возможно, есть ситуации когда bottleneck от Simple NMT все испортит, но здесь этого не наблюдается."
      ]
    },
    {
      "metadata": {
        "id": "ILAFC8KjVO1O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tatoeba"
      ]
    },
    {
      "metadata": {
        "id": "6nsZi2XzCWk2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8c5d3d90-347f-4e13-b595-f08ac812aca3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525529860614,
          "user_tz": -180,
          "elapsed": 2051,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! wget http://www.manythings.org/anki/rus-eng.zip"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-05 14:17:39--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 104.24.108.196, 104.24.109.196, 2400:cb00:2048:1::6818:6dc4, ...\n",
            "Connecting to www.manythings.org (www.manythings.org)|104.24.108.196|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6366669 (6.1M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip.1’\n",
            "\n",
            "rus-eng.zip.1       100%[===================>]   6.07M  21.7MB/s    in 0.3s    \n",
            "\n",
            "2018-05-05 14:17:40 (21.7 MB/s) - ‘rus-eng.zip.1’ saved [6366669/6366669]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4mPzIRxcIA4y",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "cc2a7113-c1bf-4df5-dd7c-15ca53ab3980",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525529865882,
          "user_tz": -180,
          "elapsed": 4599,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! unzip ./rus-eng.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./rus-eng.zip\n",
            "replace rus.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "i_QchBn4IC6n",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"./rus.txt\") as fin:\n",
        "    data = fin.readlines()\n",
        "data = list(map(lambda x: x.replace(\"\\n\", \"\").lower(), data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IstjvF2PIFZn",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = data[:int(1e5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S7YLZVHeIIWj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source = list(map(lambda x: x.split(\"\\t\")[0], data))\n",
        "target = list(map(lambda x: x.split(\"\\t\")[1], data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qjXC782IMBd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab = set(\"\".join(source).strip())\n",
        "target_vocab = set(\"\".join(target).strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ONLPyWeIN3j",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab = dict(zip(\n",
        "    list(source_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(source_vocab) + 2))))\n",
        "target_vocab = dict(zip(\n",
        "    list(target_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(target_vocab) + 2))))\n",
        "inv_target_vocab = dict(enumerate(list(target_vocab) + ['<unk>', '<pad>']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-7ojyGVmTv2w",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_simple_nmt_tatoeba(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    encoder1 = Embedding(in_chars, 128)(inputs)\n",
        "    encoder2 = LSTM(256)(encoder1)\n",
        "    encoder3 = RepeatVector(TIME_STEPS)(encoder2)\n",
        "    decoder1 = LSTM(256, return_sequences=True)(encoder3)\n",
        "    outputs = TimeDistributed(Dense(out_chars, activation='softmax'))(decoder1)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r0M0jVPEITPf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "ebcf4a2d-fea1-4e45-ec16-45f7e3758024",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525456818679,
          "user_tz": -180,
          "elapsed": 1503,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_simple_nmt_tatoeba(len(source_vocab), len(target_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_27 (InputLayer)        (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_27 (Embedding)     (None, 20, 128)           6912      \n",
            "_________________________________________________________________\n",
            "lstm_48 (LSTM)               (None, 256)               394240    \n",
            "_________________________________________________________________\n",
            "repeat_vector_4 (RepeatVecto (None, 20, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_49 (LSTM)               (None, 20, 256)           525312    \n",
            "_________________________________________________________________\n",
            "time_distributed_9 (TimeDist (None, 20, 87)            22359     \n",
            "=================================================================\n",
            "Total params: 948,823\n",
            "Trainable params: 948,823\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pY9cJDEMIiF2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = np.array([string_to_int(i, TIME_STEPS, source_vocab) for i in source])\n",
        "targets = [string_to_int(t, TIME_STEPS, target_vocab) for t in target]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Fxg1qPfmInXS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "32c8525d-a432-4842-e91f-da28c6796f9e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525458431027,
          "user_tz": -180,
          "elapsed": 1588150,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit([inputs], targets, epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 90000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "43776/90000 [=============>................] - ETA: 1:19 - loss: 2.8866 - acc: 0.2342"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 158s 2ms/step - loss: 2.7862 - acc: 0.2602 - val_loss: 2.8548 - val_acc: 0.2285\n",
            "Epoch 2/10\n",
            "11200/90000 [==>...........................] - ETA: 2:14 - loss: 2.6033 - acc: 0.3069"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.5313 - acc: 0.3237"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 159s 2ms/step - loss: 2.5313 - acc: 0.3237 - val_loss: 2.6690 - val_acc: 0.2743\n",
            "Epoch 3/10\n",
            "28608/90000 [========>.....................] - ETA: 1:44 - loss: 2.4329 - acc: 0.3480"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 159s 2ms/step - loss: 2.3937 - acc: 0.3572 - val_loss: 2.5728 - val_acc: 0.2981\n",
            "Epoch 4/10\n",
            " 5376/90000 [>.............................] - ETA: 2:24 - loss: 2.3294 - acc: 0.3731"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.2920 - acc: 0.3812"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 160s 2ms/step - loss: 2.2920 - acc: 0.3812 - val_loss: 2.5062 - val_acc: 0.3150\n",
            "Epoch 5/10\n",
            "28608/90000 [========>.....................] - ETA: 1:45 - loss: 2.2266 - acc: 0.3949"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 159s 2ms/step - loss: 2.2096 - acc: 0.3984 - val_loss: 2.4679 - val_acc: 0.3244\n",
            "Epoch 6/10\n",
            " 5376/90000 [>.............................] - ETA: 2:27 - loss: 2.1602 - acc: 0.4091"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.1418 - acc: 0.4126"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 159s 2ms/step - loss: 2.1418 - acc: 0.4126 - val_loss: 2.4336 - val_acc: 0.3334\n",
            "Epoch 7/10\n",
            "28608/90000 [========>.....................] - ETA: 1:44 - loss: 2.0910 - acc: 0.4229"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 158s 2ms/step - loss: 2.0836 - acc: 0.4248 - val_loss: 2.4167 - val_acc: 0.3386\n",
            "Epoch 8/10\n",
            " 5376/90000 [>.............................] - ETA: 2:23 - loss: 2.0380 - acc: 0.4326"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.0328 - acc: 0.4357"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 160s 2ms/step - loss: 2.0328 - acc: 0.4357 - val_loss: 2.4027 - val_acc: 0.3420\n",
            "Epoch 9/10\n",
            "28608/90000 [========>.....................] - ETA: 1:44 - loss: 1.9882 - acc: 0.4442"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 158s 2ms/step - loss: 1.9870 - acc: 0.4453 - val_loss: 2.4148 - val_acc: 0.3417\n",
            "Epoch 10/10\n",
            " 5376/90000 [>.............................] - ETA: 2:23 - loss: 1.9339 - acc: 0.4584"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 1.9465 - acc: 0.4540"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r90000/90000 [==============================] - 158s 2ms/step - loss: 1.9465 - acc: 0.4540 - val_loss: 2.4017 - val_acc: 0.3444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f081036bac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "metadata": {
        "id": "aqa7UTHqIrOZ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e1f89dbe-c812-43fa-afa9-af438b359aff",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525458472812,
          "user_tz": -180,
          "elapsed": 581,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_example(m, source_vocab, inv_target_vocab, 'hello')"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['п',\n",
              " 'о',\n",
              " 'о',\n",
              " 'о',\n",
              " 'о',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "metadata": {
        "id": "mtc9dUKVah-R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_simple_nmt_tatoeba(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    encoder1 = Embedding(in_chars, 128)(inputs)\n",
        "    encoder2 = LSTM(300, return_sequences=True)(encoder1)\n",
        "    encoder3 = LSTM(300, return_sequences=False)(encoder2)\n",
        "    encoder4 = RepeatVector(TIME_STEPS)(encoder3)\n",
        "    decoder1 = LSTM(300, return_sequences=True)(encoder4)\n",
        "    outputs = TimeDistributed(Dense(out_chars, activation='softmax'))(decoder1)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1M-dHRVzaiuc",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "a3f0c038-0209-4751-bfa4-81229793e1f0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525462624436,
          "user_tz": -180,
          "elapsed": 1832,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_simple_nmt_tatoeba(len(source_vocab), len(target_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 20, 128)           6912      \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 20, 300)           514800    \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (None, 300)               721200    \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 20, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 20, 300)           721200    \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 20, 87)            26187     \n",
            "=================================================================\n",
            "Total params: 1,990,299\n",
            "Trainable params: 1,990,299\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HiQkl-7ZakVo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "e6bfdefb-e61b-439c-f0dd-d68c3375ff56",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525464836573,
          "user_tz": -180,
          "elapsed": 2211183,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit([inputs], targets, epochs=10, batch_size=64, validation_split=0.1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 90000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "43776/90000 [=============>................] - ETA: 1:52 - loss: 2.8896 - acc: 0.2344"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 223s 2ms/step - loss: 2.7936 - acc: 0.2593 - val_loss: 2.8449 - val_acc: 0.2291\n",
            "Epoch 2/10\n",
            "11136/90000 [==>...........................] - ETA: 3:08 - loss: 2.6189 - acc: 0.3043"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.5450 - acc: 0.3206"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 222s 2ms/step - loss: 2.5450 - acc: 0.3206 - val_loss: 2.6828 - val_acc: 0.2718\n",
            "Epoch 3/10\n",
            "28608/90000 [========>.....................] - ETA: 2:26 - loss: 2.4379 - acc: 0.3465"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 221s 2ms/step - loss: 2.4022 - acc: 0.3555 - val_loss: 2.5743 - val_acc: 0.2997\n",
            "Epoch 4/10\n",
            " 5312/90000 [>.............................] - ETA: 3:23 - loss: 2.3327 - acc: 0.3703"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.2940 - acc: 0.3804"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 222s 2ms/step - loss: 2.2940 - acc: 0.3804 - val_loss: 2.5029 - val_acc: 0.3160\n",
            "Epoch 5/10\n",
            "28608/90000 [========>.....................] - ETA: 2:26 - loss: 2.2225 - acc: 0.3956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 220s 2ms/step - loss: 2.2002 - acc: 0.4001 - val_loss: 2.4501 - val_acc: 0.3281\n",
            "Epoch 6/10\n",
            " 5312/90000 [>.............................] - ETA: 3:19 - loss: 2.1350 - acc: 0.4129"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 2.1180 - acc: 0.4173"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 219s 2ms/step - loss: 2.1180 - acc: 0.4173 - val_loss: 2.4102 - val_acc: 0.3380\n",
            "Epoch 7/10\n",
            "28608/90000 [========>.....................] - ETA: 2:24 - loss: 2.0529 - acc: 0.4303"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 220s 2ms/step - loss: 2.0450 - acc: 0.4322 - val_loss: 2.3851 - val_acc: 0.3443\n",
            "Epoch 8/10\n",
            " 5376/90000 [>.............................] - ETA: 3:22 - loss: 1.9865 - acc: 0.4450"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 1.9797 - acc: 0.4463"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 220s 2ms/step - loss: 1.9797 - acc: 0.4463 - val_loss: 2.3745 - val_acc: 0.3482\n",
            "Epoch 9/10\n",
            "28608/90000 [========>.....................] - ETA: 2:29 - loss: 1.9217 - acc: 0.4580"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 222s 2ms/step - loss: 1.9207 - acc: 0.4585 - val_loss: 2.3688 - val_acc: 0.3505\n",
            "Epoch 10/10\n",
            " 5312/90000 [>.............................] - ETA: 3:19 - loss: 1.8526 - acc: 0.4725"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "89984/90000 [============================>.] - ETA: 0s - loss: 1.8656 - acc: 0.4705"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r90000/90000 [==============================] - 220s 2ms/step - loss: 1.8656 - acc: 0.4705 - val_loss: 2.3698 - val_acc: 0.3544\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f623fe3f9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Zvlarwkralq6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "cfe28e20-46b9-41e3-d4c8-34e08e8139a2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525465287327,
          "user_tz": -180,
          "elapsed": 793,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_example(m, source_vocab, inv_target_vocab, 'hello')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['п',\n",
              " 'р',\n",
              " 'п',\n",
              " 'о',\n",
              " 'а',\n",
              " 'т',\n",
              " 'т',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "Q5PGocndkvW4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 50\n",
        "EMBEDING = 256\n",
        "ENCODER_UNITS = 512\n",
        "DECODER_UNITS = 512"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7gey3VPZ6yIt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = np.array([string_to_int(i, TIME_STEPS, source_vocab) for i in source])\n",
        "targets = [string_to_int(t, TIME_STEPS, target_vocab) for t in target]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LewOHjg-kRsv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_attention_nmt_tatoeba(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    embeding = Embedding(in_chars, EMBEDING)(inputs)\n",
        "    lstm = LSTM(ENCODER_UNITS, return_sequences=True)(embeding)\n",
        "    attention = attention_cell(lstm)\n",
        "    lstm = LSTM(ENCODER_UNITS, return_sequences=True)(attention)\n",
        "    lstm = LSTM(DECODER_UNITS, return_sequences=True)(lstm)\n",
        "    outputs = TimeDistributed(Dense(out_chars, activation='softmax'))(lstm)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8YWlRmdkqyY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "da58ce4d-4aab-4a85-f21d-d8ad7a330a0a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525529905908,
          "user_tz": -180,
          "elapsed": 3051,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_attention_nmt_tatoeba(len(source_vocab), len(target_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 50)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 50, 256)      13824       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 50, 512)      1574912     embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "permute_1 (Permute)             (None, 512, 50)      0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512, 50)      2550        permute_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 50, 512)      0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, 50, 512)      0           lstm_2[0][0]                     \n",
            "                                                                 permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 50, 512)      2099200     multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 50, 512)      2099200     lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed_1 (TimeDistrib (None, 50, 87)       44631       lstm_4[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,834,317\n",
            "Trainable params: 5,834,317\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8UV5eNs1krNS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "6fee4d58-70c3-49ec-a77a-94902bd20ff1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525532183949,
          "user_tz": -180,
          "elapsed": 2275548,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit([inputs], targets, epochs=10, batch_size=256, validation_split=0.1)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 90000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "90000/90000 [==============================] - 230s 3ms/step - loss: 1.4614 - acc: 0.6491 - val_loss: 1.6260 - val_acc: 0.5873\n",
            "Epoch 2/10\n",
            "43520/90000 [=============>................] - ETA: 1:53 - loss: 1.3088 - acc: 0.6661"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.2923 - acc: 0.6694 - val_loss: 1.5623 - val_acc: 0.5998\n",
            "Epoch 3/10\n",
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.2335 - acc: 0.6811 - val_loss: 1.5126 - val_acc: 0.6093\n",
            "Epoch 4/10\n",
            " 3840/90000 [>.............................] - ETA: 3:29 - loss: 1.2057 - acc: 0.6866"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.1834 - acc: 0.6927 - val_loss: 1.4817 - val_acc: 0.6183\n",
            "Epoch 5/10\n",
            "81664/90000 [==========================>...] - ETA: 20s - loss: 1.1371 - acc: 0.7040"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.1349 - acc: 0.7045 - val_loss: 1.4173 - val_acc: 0.6325\n",
            "Epoch 6/10\n",
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.0905 - acc: 0.7140 - val_loss: 1.3907 - val_acc: 0.6376\n",
            "Epoch 7/10\n",
            "12800/90000 [===>..........................] - ETA: 3:08 - loss: 1.0628 - acc: 0.7197"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.0537 - acc: 0.7210 - val_loss: 1.3725 - val_acc: 0.6428\n",
            "Epoch 8/10\n",
            "84992/90000 [===========================>..] - ETA: 12s - loss: 1.0203 - acc: 0.7271"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 227s 3ms/step - loss: 1.0196 - acc: 0.7273 - val_loss: 1.3464 - val_acc: 0.6480\n",
            "Epoch 9/10\n",
            "90000/90000 [==============================] - 227s 3ms/step - loss: 0.9873 - acc: 0.7328 - val_loss: 1.3330 - val_acc: 0.6503\n",
            "Epoch 10/10\n",
            "13568/90000 [===>..........................] - ETA: 3:06 - loss: 0.9596 - acc: 0.7376"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "90000/90000 [==============================] - 227s 3ms/step - loss: 0.9564 - acc: 0.7386 - val_loss: 1.3222 - val_acc: 0.6527\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f06fc2e3b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "O-AyXoebks93",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "ea391819-6c0a-4f0f-dd12-1797a1f71041",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525532394377,
          "user_tz": -180,
          "elapsed": 878,
          "user": {
            "displayName": "Evgeny Rubanenko",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "102476666956781355563"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_example(m, source_vocab, inv_target_vocab, 'hello')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['п',\n",
              " 'о',\n",
              " 'с',\n",
              " 'о',\n",
              " 'е',\n",
              " 'и',\n",
              " 'е',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>',\n",
              " '<pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "LG7Vaw6-VKry",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Report\n",
        "\n",
        "1. Решил попробовать запустить здесь Simple NMT. Увеличил число нейронов в сети. Получил на валидации 0.34.\n",
        "2. Решил добавить слоев в енкодер и декодер. Стало 0.35.\n",
        "3. Поставил после первой LSTM Attention cell, а потом две LSTM + увеличил TIME_STEPS + увеличил batch_size (потому что долго считалось). Получил 0.65 на валидации. Перевод правда так себе.\n",
        "\n",
        "*Еще я пробовал использовать Bidirectional, комбинации нескольких LSTM, \"подавать все output на вход следующему слою, или только один\", но получал что-то в районе 0.44.*"
      ]
    },
    {
      "metadata": {
        "id": "DUzXSaKpVdb2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}